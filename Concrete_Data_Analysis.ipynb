{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete = pd.read_csv(\"data/Concrete_Data.csv\")\n",
    "# Rename the columns\n",
    "concrete.columns = [\"cement\", \"slag\", \"ash\", \"water\", \"splast\", \"coarse\", \"fine\", \"age\", \"strength\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>ash</th>\n",
       "      <th>water</th>\n",
       "      <th>splast</th>\n",
       "      <th>coarse</th>\n",
       "      <th>fine</th>\n",
       "      <th>age</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement   slag  ash  water  splast  coarse   fine  age  strength\n",
       "0   540.0    0.0  0.0  162.0     2.5  1040.0  676.0   28     79.99\n",
       "1   540.0    0.0  0.0  162.0     2.5  1055.0  676.0   28     61.89\n",
       "2   332.5  142.5  0.0  228.0     0.0   932.0  594.0  270     40.27\n",
       "3   332.5  142.5  0.0  228.0     0.0   932.0  594.0  365     41.05\n",
       "4   198.6  132.4  0.0  192.0     0.0   978.4  825.5  360     44.30"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1030 entries, 0 to 1029\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   cement    1030 non-null   float64\n",
      " 1   slag      1030 non-null   float64\n",
      " 2   ash       1030 non-null   float64\n",
      " 3   water     1030 non-null   float64\n",
      " 4   splast    1030 non-null   float64\n",
      " 5   coarse    1030 non-null   float64\n",
      " 6   fine      1030 non-null   float64\n",
      " 7   age       1030 non-null   int64  \n",
      " 8   strength  1030 non-null   float64\n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 72.5 KB\n"
     ]
    }
   ],
   "source": [
    "concrete.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples, number_of_features  = concrete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing X and Y according to shape and converting to numpy arrays\n",
    "X = concrete.iloc[:,0:number_of_features-1].values\n",
    "y = concrete.iloc[:,number_of_features-1:number_of_features].values\n",
    "\n",
    "#Initializing theta\n",
    "theta = np.zeros((number_of_features,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_normalization(X):\n",
    "    \"\"\"\n",
    "    Normalizes the features in X. returns a normalized version of X where\n",
    "    the mean value of each feature is 0 and the standard deviation\n",
    "    is 1. This is often a good preprocessing step to do when working with\n",
    "    learning algorithms.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The dataset of shape (m x n).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_normalized : array_like\n",
    "        The normalized dataset of shape (m x n).\n",
    "    mean: array_like\n",
    "        Mean of every column\n",
    "    standard_deviation : array_like\n",
    "        Standard Deviation of every column\n",
    "    \"\"\"\n",
    "    standard_deviation = np.std(X, axis= 0)\n",
    "    mean = np.mean(X, axis= 0)\n",
    "    X_normalized = (X - mean)/ standard_deviation\n",
    "    \n",
    "    return X_normalized, mean, standard_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_X, mean_X, standard_deviation_X = feature_normalization(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the columns of 1s to X \n",
    "X = np.concatenate((np.ones((number_of_samples,1)),normalized_X), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(X,y,theta):\n",
    "    \"\"\"\n",
    "    Compute cost for linear regression with multiple variables.\n",
    "    Computes the cost of using theta as the parameter for linear regression to fit the data points in X and y.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The dataset of shape (m x n+1).\n",
    "    \n",
    "    y : array_like\n",
    "        A vector of shape (m, ) for the values at a given data point.\n",
    "    \n",
    "    theta : array_like\n",
    "        The linear regression parameters. A vector of shape (n+1, )\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    J : float\n",
    "        The value of the cost function. \n",
    "    \"\"\"\n",
    "    #Initialisation of useful values \n",
    "    m = np.size(y)\n",
    "    J = 0\n",
    "    \n",
    "    #Hypothesis function in vectorized form\n",
    "    h = np.dot(X,theta)\n",
    "\n",
    "    #Cost function in vectorized form\n",
    "    J = float((1./(2*m)) * np.dot((h - y).T, (h - y)));    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta, learning_rate = 0.0005, iteration=1000):\n",
    "    \"\"\"\n",
    "    Performs gradient descent to learn theta.\n",
    "    Updates theta by taking num_iters gradient steps with learning rate alpha.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The dataset of shape (m x n+1).\n",
    "    \n",
    "    y : array_like\n",
    "        A vector of shape (m, ) for the values at a given data point.\n",
    "    \n",
    "    theta : array_like\n",
    "        The linear regression parameters. A vector of shape (n+1, )\n",
    "    \n",
    "    learning_rate : float\n",
    "        The learning rate for gradient descent. \n",
    "    \n",
    "    iteration : int\n",
    "        The number of iterations to run gradient descent. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    theta : array_like\n",
    "        The learned linear regression parameters. A vector of shape (n+1, ).\n",
    "    \n",
    "    J_history : list\n",
    "        A python list for the values of the cost function after each iteration.\n",
    "        \n",
    "    theta_history : list\n",
    "        A python list for the values of theta per each iteration and store them in a list\n",
    "    \n",
    "    \"\"\"\n",
    "    #Initialisation of useful values \n",
    "    m = np.size(y)\n",
    "    J_history = np.zeros(iteration)\n",
    "\n",
    "    for i in range(iteration):\n",
    "        #Hypothesis function\n",
    "        h = np.dot(X,theta)\n",
    "        \n",
    "        #Calculating the grad function in vectorized form\n",
    "        theta = theta - learning_rate * (1/m)* (X.T.dot(h-y))\n",
    "        J_history[i] = cost_function(X,y,theta)\n",
    "    optimized_hypothesis= h\n",
    "    return theta, J_history, optimized_hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameter - theta is defined before\n",
    "learning_rate= .1\n",
    "iteration= 1000\n",
    "# run gradient descent\n",
    "theta_optimized , cost_function_history, optimized_hypothesis= gradient_descent(X, y, theta, learning_rate, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize= (12,7))\n",
    "plt.plot(range(1000), cost_function_history, color= \"teal\", linewidth= 3)\n",
    "plt.xlabel(\"# Iteration\")\n",
    "plt.ylabel(\"Cost Value\")\n",
    "plt.title(\"Cost value during Iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_squared(predicted_hypothesis, actual_y):\n",
    "    \"\"\"\n",
    "    Calculate r_squared parameter for model accuracy\n",
    "    range of output is between 0 and 1, when accuracy is higher means we have better model.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    predicted_hypothesis : array_like\n",
    "        Best theta dot X that is out best prediction.\n",
    "    \n",
    "    actual_y : array_like\n",
    "        Actual values of our dataset, the column that is our answer.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    r_squared : float\n",
    "        Model accuracy, higher is better (most of the time)\n",
    "    \"\"\"\n",
    "    # parameters\n",
    "    sum_of_squared_residuals= np.sum(np.square(actual_y - predicted_hypothesis))\n",
    "    \n",
    "    sum_of_squared_total= np.sum(np.square(actual_y - np.mean(actual_y)))\n",
    "    \n",
    "    r_squared= 1 - ((float(sum_of_squared_residuals))/sum_of_squared_total)\n",
    "    \n",
    "    return r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared for Linear Regression is: 0.6154832293742327\n"
     ]
    }
   ],
   "source": [
    "r_squared_predicted= r_squared(optimized_hypothesis, y)\n",
    "print(\"R Squared for Linear Regression is: {}\".format(r_squared_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_r_squared(r_squared, actual_y):\n",
    "    \"\"\"\n",
    "    Find out adjusted_r_squared parameter for model accuracy\n",
    "    range of output is between 0 and 1, when accuracy is higher means we have better model.\n",
    "    instead of r_squared this metric is better option for reports\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    r_squared : float\n",
    "        r_squared value metric.\n",
    "    \n",
    "    actual_y : array_like\n",
    "        Actual values of our dataset, the column that is our answer.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    adjusted_r_squared : float\n",
    "        Model accuracy, higher is better (most of the time)\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize values\n",
    "    number_of_samples, number_of_features= X.shape\n",
    "    # number of features have surplus value because of intercept values that we added a vector for another features\n",
    "    number_of_features -= 1\n",
    "    # adjusted R squared formula\n",
    "    adjusted_r_squared= 1 - (1 - r_squared) * (number_of_samples - 1)/(number_of_samples - number_of_features - 1)\n",
    "    return adjusted_r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R Squared for Linear Regression is: 0.6124703653536586\n"
     ]
    }
   ],
   "source": [
    "adjusted_r_squared_predicted= adjusted_r_squared(r_squared_predicted, y)\n",
    "print(\"Adjusted R Squared for Linear Regression is: {}\".format(adjusted_r_squared_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized theta: [[35.81796117]\n",
      " [12.25484493]\n",
      " [ 8.70283503]\n",
      " [ 5.40277888]\n",
      " [-3.4258435 ]\n",
      " [ 1.71476931]\n",
      " [ 1.20250345]\n",
      " [ 1.36604147]\n",
      " [ 7.20440571]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimized theta: {}\".format(theta_optimized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation with Normal Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete = pd.read_csv(\"data/Concrete_Data.csv\")\n",
    "# Rename the columns\n",
    "concrete.columns = [\"cement\", \"slag\", \"ash\", \"water\", \"splast\", \"coarse\", \"fine\", \"age\", \"strength\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing X and Y according to shape and converting to numpy arrays\n",
    "X = concrete.iloc[:,0:number_of_features-1].values\n",
    "y = concrete.iloc[:,number_of_features-1:number_of_features].values\n",
    "\n",
    "#Initializing theta\n",
    "theta = np.zeros((number_of_features,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the columns of 1s to X \n",
    "X = np.concatenate((np.ones((number_of_samples,1)),normalized_X), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    \"\"\"\n",
    "    Computes the closed-form solution to linear regression using the normal equations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The dataset of shape (m x n+1).\n",
    "    \n",
    "    y : array_like\n",
    "        The value at each data point. A vector of shape (m, ).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    theta : array_like\n",
    "        Estimated linear regression parameters. A vector of shape (n+1, ).\n",
    "    \"\"\"\n",
    "    # initialize theta with zero values\n",
    "    theta = np.zeros(X.shape[1])\n",
    "    theta = np.dot(np.dot(np.linalg.pinv(np.dot(X.T, X)), X.T), y)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = normal_equation(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_hypothesis_with_normal_equation= np.dot(X, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared for Linear Regression is: 0.6155198704142721\n"
     ]
    }
   ],
   "source": [
    "r_squared_predicted_with_normal_equation= r_squared(optimized_hypothesis_with_normal_equation, y)\n",
    "print(\"R Squared for Linear Regression is: {}\".format(r_squared_predicted_with_normal_equation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R Squared for Linear Regression is: 0.6125072934929344\n"
     ]
    }
   ],
   "source": [
    "adjusted_r_squared_predicted_with_normal_equation= adjusted_r_squared(r_squared_predicted_with_normal_equation, y)\n",
    "print(\"Adjusted R Squared for Linear Regression is: {}\".format(adjusted_r_squared_predicted_with_normal_equation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
